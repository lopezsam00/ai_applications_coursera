{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9ead3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# IBM WatsonX imports\n",
    "from ibm_watsonx_ai.foundation_models import Model\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n",
    "\n",
    "from langchain_ibm import WatsonxLLM\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableSequence\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.chains import LLMChain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4501d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_model(prompt_txt, params=None):\n",
    "    \n",
    "    model_id = \"ibm/granite-3-2-8b-instruct\"\n",
    "    \n",
    "    default_params = {\n",
    "        \"max_new_tokens\": 256,\n",
    "        \"min_new_tokens\": 0,\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_p\": 0.2,\n",
    "        \"top_k\": 1\n",
    "    }\n",
    "    \n",
    "    if params:\n",
    "        default_params.update(params)\n",
    "    \n",
    "    # Set up credentials for WatsonxLLM\n",
    "    url = os.getenv(\"IBM_URL_END_POINT\")\n",
    "    apikey = os.getenv(\"IBM_API_KEY\")\n",
    "    username = os.getenv(\"WATSONX_USERNAME\")\n",
    "    project_id = os.getenv(\"IBM_PROJECT_ID\")\n",
    "    \n",
    "    # Create LLM directly\n",
    "    granite_llm = WatsonxLLM(\n",
    "        model_id=model_id,\n",
    "        apikey=apikey,\n",
    "        username=username,\n",
    "        project_id=project_id,\n",
    "        params=default_params,\n",
    "        url=url\n",
    "    )\n",
    "    \n",
    "    response = granite_llm.invoke(prompt_txt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3291cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GenParams().get_example_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f6ee283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: I have a really cute cockatiel that loves to \n",
      "\n",
      "response : ride on my shoulder. I want to take him with me on a trip to the beach. Is it safe for him to be there?\n",
      "\n",
      "While it's tempting to bring your cockatiel along for a beach trip, it's important to consider several factors to ensure his safety and well-being. Here are some points to keep in mind:\n",
      "\n",
      "1. **Temperature and Humidity:** Cockatiels are sensitive to extreme temperatures and high humidity. The beach environment can be quite hot and humid, which may cause heat stress or respiratory issues for your bird.\n",
      "\n",
      "2. **Noise and Crowds:** Beaches are often noisy and crowded, which can be overwhelming and\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_new_tokens\": 158,\n",
    "    \"min_new_tokens\": 10,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 0.2,\n",
    "    \"top_k\": 1\n",
    "}\n",
    "\n",
    "prompt = \"I have a really cute cockatiel that loves to \"\n",
    "\n",
    "# Getting a reponse from the model with the provided prompt and new parameters\n",
    "response = llm_model(prompt, params)\n",
    "print(f\"prompt: {prompt}\\n\")\n",
    "print(f\"response : {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cfcd5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: Classify the following statement as true or false: \n",
      "            'The Eiffel Tower is located in Berlin.'\n",
      "\n",
      "            Answer:\n",
      "\n",
      "\n",
      "response : \n",
      "False. The Eiffel Tower is located in Paris, France.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Zero shot prompt\n",
    "prompt = \"\"\"Classify the following statement as true or false: \n",
    "            'The Eiffel Tower is located in Berlin.'\n",
    "\n",
    "            Answer:\n",
    "\"\"\"\n",
    "response = llm_model(prompt, params)\n",
    "print(f\"prompt: {prompt}\\n\")\n",
    "print(f\"response : {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b1c822d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MOVIE_REVIEW RESPONSE ===\n",
      ". The acting was superb, and the soundtrack was hauntingly beautiful. However, the pacing was a bit slow, and the ending was somewhat predictable.'\"\n",
      "\n",
      "The movie review is positive. The reviewer praises the visuals, storyline, acting, and soundtrack, using words like \"stunning,\" \"gripping,\" \"superb,\" and \"hauntingly beautiful.\" Despite mentioning some drawbacks, such as slow pacing and a predictable ending, the overall tone and specific positive comments indicate a favorable opinion of the movie.\n",
      "\n",
      "=== CLIMATE_CHANGE RESPONSE ===\n",
      " weather events, and threats to biodiversity.\n",
      "\n",
      "Climate change, driven by human activities like fossil fuel burning and deforestation, results in significant global temperature shifts, severe weather events, and biodiversity threats, despite its natural occurrence.\n",
      "\n",
      "=== TRANSLATION RESPONSE ===\n",
      "\n",
      "\n",
      "Translation: 'Technology advances rapidly in the modern world.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Starter code: provide your solutions in the TODO parts\n",
    "\n",
    "# 1. Prompt for Movie Review Classification\n",
    "movie_review_prompt = \"\"\"\"Determine if the following movie review is positive or negative:\n",
    "'The movie had stunning visuals and a gripping storyline that kept me on the edge of my seat\"\"\"\n",
    "\n",
    "# 2. Prompt for Climate Change Paragraph Summarization\n",
    "climate_change_prompt = \"\"\"Summarize the following paragraph about climate change in one sentence:\n",
    "Climate change refers to significant changes in global temperatures and weather patterns over time. \n",
    "While climate change is a natural phenomenon, \n",
    "scientific evidence shows that human activities, \n",
    "particularly the burning of fossil fuels and deforestation, have accelerated the process. \n",
    "The consequences of climate change include rising sea levels, more frequent and severe\"\"\"\n",
    "\n",
    "# 3. Prompt for English to Spanish Translation\n",
    "translation_prompt = \"\"\"Traduzca la siguiente oracion al ingles: 'La tecnologia avanza rapidamente en el mundo moderno.'\"\"\"\n",
    "\n",
    "responses = {}\n",
    "responses[\"movie_review\"] = llm_model(movie_review_prompt, params)\n",
    "responses[\"climate_change\"] = llm_model(climate_change_prompt, params)\n",
    "responses[\"translation\"] = llm_model(translation_prompt, params)\n",
    "\n",
    "for prompt_type, response in responses.items():\n",
    "    print(f\"=== {prompt_type.upper()} RESPONSE ===\")\n",
    "    print(response)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
